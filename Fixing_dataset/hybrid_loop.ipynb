{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43586655-7c90-4d07-b6a1-d1a33af73c42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "import pprint\n",
    "from datasets import load_dataset\n",
    "import openai\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from IPython.display import display, HTML\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2bdb347a-21bb-481b-9958-d6a9ab9b7bf6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())  # Should return True if CUDA is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d94d83a4-e261-4e6f-b7e6-b07beac44a4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reading API Key from file\n",
    "API_KEY = open(\"open_ai_API.txt\", \"r\").read().strip()\n",
    "openai.api_key = API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ad8f4dc-feb8-42e0-9b68-bdaf7adccc0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "561271be-b191-4597-803e-410925595ad6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = load_dataset(\"generaleoley/manim-codegen\", split='train')\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7ea1602b-f227-4ddb-9880-8467636905c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def similarity_f(embedded_open_gen,text, model):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity between the embeddings of two text inputs.\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "    text1 (str): \n",
    "        The first input text that will be encoded and compared.\n",
    "    \n",
    "    text2 (str): \n",
    "        The second input text that will be encoded and compared.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    float: \n",
    "        A floating-point value representing the cosine similarity between the two text embeddings. The value ranges\n",
    "        between -1 and 1:\n",
    "        - 1 indicates that the texts are identical in terms of the embedding space.\n",
    "        - 0 indicates that the texts are orthogonal (no similarity).\n",
    "        - -1 indicates maximum dissimilarity in terms of the embedding space.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    embedding = model.encode(text, convert_to_tensor=True)\n",
    "    return util.pytorch_cos_sim(embedded_open_gen, embedding).item()\n",
    "\n",
    "def create_message_for_comparison(code_snippet, paragraphs):\n",
    "    \"\"\"\n",
    "    Compares the prompts with the highest cosine similarity to ultimately find the correct prompt for the code \n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "    code_snippet (str):\n",
    "        A string containing the Python code that will be compared against the provided paragraphs.\n",
    "    \n",
    "    paragraphs (list of str):\n",
    "        A list of paragraphs (prompts) to be compared with the Python code. Each paragraph is a potential\n",
    "        candidate that could have generated the provided code snippet.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    list:\n",
    "        A list containing two dictionaries, formatted as messages:\n",
    "        1. A system message that defines the role and behavior of the model.\n",
    "        2. A user message that contains the code snippet and the paragraphs for comparison.\n",
    "    \"\"\"\n",
    "    # System message to guide GPT's behavior\n",
    "    system_message = {\n",
    "        \"role\": \"system\",\n",
    "        # \"content\": \"You are an assistant that compares Python code snippets with paragraphs and finds the most similar match.\"\n",
    "        \"content\": \"You are an assistant that compares prompts to find the one which most likely generated the provided code\"\n",
    "    }\n",
    "    \n",
    "    # User message that provides the code and paragraphs\n",
    "    user_message_content = f\"\"\"\n",
    "    Here is the Python code snippet:\n",
    "    \n",
    "    ```python\n",
    "    {code_snippet}\n",
    "    ```\n",
    "\n",
    "    Below are the prompts {len(paragraphs)}. Compare each prompt with the provided code snippet and determine which prompt is the most similar to the code. Provide the index of the most similar prompt and print that prompt under ** ** without paragraph index or anything else.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Append each paragraph with its index\n",
    "    for i, paragraph in enumerate(paragraphs, start=1):\n",
    "        user_message_content += f\"\\nParagraph {i}: {paragraph}\"\n",
    "    \n",
    "    user_message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_message_content\n",
    "    }\n",
    "    \n",
    "    return [system_message, user_message]\n",
    "\n",
    "# Isolates output and runs a search for it through the dataset to find its corresponding index in the dataset\n",
    "def searching(response, reference):\n",
    "    search_phrase = response[20:-15]  # Skip the first 15 characters\n",
    "    # Search for the phrase in the 'query' column and store the row number\n",
    "    filtered_rows_with_indices_query = [(index, example) for index, example in enumerate(data) if search_phrase.lower() in example['query'].lower()]\n",
    "\n",
    "    print(\"Reference =\", reference,\",  No. of instances =\",len(filtered_rows_with_indices_query))\n",
    "\n",
    "    # Display the filtered rows with their corresponding row numbers\n",
    "    for index, row in filtered_rows_with_indices_query:\n",
    "        print(f\"Row {index}:\")\n",
    "        # print(row['query'])\n",
    "\n",
    "    result = [(reference, index, row['query']) for index, row in filtered_rows_with_indices_query]\n",
    "    \n",
    "\n",
    "def searching2(response, reference):\n",
    "    \"\"\"\n",
    "    Isolates the output and runs a search through the dataset to find its corresponding index in the dataset.\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "    response (str): \n",
    "        The response text to search for in the dataset. The phrase is extracted by removing the first and last 15 characters.\n",
    "\n",
    "    reference (int): \n",
    "        The reference number associated with this search.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    list: \n",
    "        A list of tuples where each tuple contains the reference and the index of the matching row.\n",
    "    \"\"\"\n",
    "    \n",
    "    search_phrase = response[20:-15]  # Skip the first 15 characters and the last 15 characters\n",
    "    \n",
    "    # Search for the phrase in the 'query' column and store the row index\n",
    "    filtered_rows_with_indices_query = [index for index, example in enumerate(data) if search_phrase.lower() in example['query'].lower()]\n",
    "\n",
    "    # Only return reference and index, not the full example\n",
    "    result = [(reference, index) for index in filtered_rows_with_indices_query]\n",
    "    \n",
    "    return result\n",
    "\n",
    "    \n",
    "\n",
    "def printer(printing_content):\n",
    "    \"\"\"\n",
    "    Displays content in a formatted HTML output with word wrapping.\n",
    "\n",
    "    This function takes a string input and displays it using IPython's display capabilities, ensuring that\n",
    "    the text is wrapped appropriately (i.e., long lines of text won't overflow the display area). It uses \n",
    "    HTML's `pre-wrap` style to preserve spaces and newlines while also wrapping text for better readability.\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "    printing_content (str):\n",
    "        The content to be displayed. This can be any text or string that should be printed with word wrapping.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    None:\n",
    "        The function outputs the wrapped content to the notebook using IPython's `display` and `HTML` functions,\n",
    "        but it does not return any value.\n",
    "    \"\"\"\n",
    "    # Display the output with word wrapping\n",
    "    wrapped_output = f\"<div style='white-space: pre-wrap;'>{printing_content}</div>\"\n",
    "    return display(HTML(wrapped_output))\n",
    "\n",
    "# Isolates output and runs a search for it through the dataset to find its corresponding index in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e12fa402-14ef-4b39-9031-7789d6f0530e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 771)]\n",
      "[(1, 990)]\n",
      "[]\n",
      "[(3, 615)]\n",
      "[(4, 737)]\n",
      "[(5, 878)]\n",
      "[(6, 771)]\n",
      "[(7, 385)]\n",
      "[(8, 751)]\n",
      "[(9, 321)]\n",
      "[]\n",
      "[(11, 385)]\n",
      "[(12, 818)]\n",
      "[(13, 156)]\n",
      "[(14, 627)]\n",
      "[(15, 452)]\n",
      "[(16, 57)]\n",
      "[(17, 1018)]\n",
      "[(18, 92)]\n",
      "[(19, 362)]\n",
      "[(20, 755)]\n",
      "[(21, 540)]\n",
      "[(22, 558)]\n",
      "[(23, 49)]\n",
      "[(24, 797)]\n",
      "[(25, 196)]\n",
      "[(26, 667)]\n",
      "[(27, 535)]\n",
      "[(28, 937)]\n",
      "[(29, 918)]\n",
      "[(30, 117)]\n",
      "[(31, 308)]\n",
      "[(32, 314)]\n",
      "[(33, 287)]\n",
      "[(34, 447)]\n",
      "[(35, 116)]\n",
      "[(36, 223)]\n",
      "[(37, 556)]\n",
      "[(38, 84)]\n",
      "[(39, 193)]\n",
      "[(40, 206)]\n",
      "[(41, 804)]\n",
      "[(42, 798)]\n",
      "[(43, 663)]\n",
      "[(44, 328)]\n",
      "[(45, 643)]\n",
      "[(46, 631)]\n",
      "[(47, 933)]\n",
      "[(48, 1001)]\n",
      "[(49, 771)]\n",
      "[(50, 246)]\n",
      "[(51, 40)]\n",
      "[]\n",
      "[(53, 777)]\n",
      "[(54, 833)]\n",
      "[(55, 225)]\n",
      "[(56, 532)]\n",
      "[(57, 927)]\n",
      "[]\n",
      "[(59, 576)]\n",
      "[(60, 351)]\n",
      "[(61, 303)]\n",
      "[]\n",
      "[]\n",
      "[(64, 613)]\n",
      "[(65, 229)]\n",
      "[(66, 146)]\n",
      "[(67, 64)]\n",
      "[(68, 537)]\n",
      "[(69, 641)]\n",
      "[(70, 810)]\n",
      "[(71, 813)]\n",
      "[(72, 699)]\n",
      "[(73, 615)]\n",
      "[(74, 817)]\n",
      "[(75, 62)]\n",
      "[(76, 782)]\n",
      "[(77, 919)]\n",
      "[(78, 751)]\n",
      "[(79, 707)]\n",
      "[(80, 118)]\n",
      "[(81, 254)]\n",
      "[(82, 445)]\n",
      "[(83, 862)]\n",
      "[(84, 978)]\n",
      "[(85, 843)]\n",
      "[(86, 552)]\n",
      "[(87, 540)]\n",
      "[(88, 732)]\n",
      "[(89, 152)]\n",
      "[(90, 890)]\n",
      "[(91, 802)]\n",
      "[(92, 722)]\n",
      "[(93, 109)]\n",
      "[(94, 544)]\n",
      "[(95, 510)]\n",
      "[(96, 163)]\n",
      "[(97, 540)]\n",
      "[(98, 716)]\n",
      "[(99, 984)]\n",
      "Exectution time : 2971.8626754283905\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#Choosing a specific code from the dataset by giving value of 'reference', change value for each code \n",
    "\n",
    "sorted_set = []\n",
    "\n",
    "for i in range(100):\n",
    "    \n",
    "    reference = i\n",
    "    code_string = data[reference]['answer']\n",
    "    formatted_code_string = code_string.replace('\\\\n', '\\n')\n",
    "    # print(formatted_code_string)\n",
    "\n",
    "    # Prepare the messages for the Chat API which will be used later for cosine similarity\n",
    "    messages = [\n",
    "        # {\"role\": \"system\", \"content\": \"You are a helpful assistant that performs semantic analysis.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Explain the purpose of this code wihtout getting into technical details, \\n\\nParagraph 1:\\n{formatted_code_string}\"},\n",
    "\n",
    "        {\"role\": \"user\", \"content\": f\"In detail, explain what is happening with the visuals,  \\n\\nParagraph 1:\\n{formatted_code_string} \"}\n",
    "    ]\n",
    "\n",
    "    # Make the API call\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",  # Or another model as appropriate\n",
    "        messages=messages,\n",
    "        max_tokens=700,  # Adjust based on your needs\n",
    "        temperature=0.01  # Adjust for more creativity or precision\n",
    "    )\n",
    "    open_gen = response.choices[0].message.content\n",
    "    # printer(open_gen)\n",
    "    \n",
    "    top_similarities = []  # List to store (similarity, index) tuples\n",
    "    top_n = 10  # Number of top similarities to keep\n",
    "    model1 = SentenceTransformer('all-MiniLM-L6-v2').to(device)\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        query_response = data[i]['query']\n",
    "        open_gen_encoded = model1.encode(open_gen, convert_to_tensor=True)\n",
    "        score = similarity_f(open_gen_encoded, query_response, model=model1)\n",
    "\n",
    "        # Add the current score and index as a dictionary to the list\n",
    "        top_similarities.append({'score': score, 'index': i, 'query': data[i]['query']})  # Storing the score and index in a dictionary\n",
    "\n",
    "        # Sort the list by similarity score in descending order and keep only the top N\n",
    "        top_similarities = sorted(top_similarities, key=lambda x: x['score'], reverse=True)[:top_n]\n",
    "\n",
    "    \n",
    "    all_scores = [item['score'] for item in top_similarities]\n",
    "    all_indices = [item['index'] for item in top_similarities]\n",
    "    all_queries = [item['query'] for item in top_similarities]\n",
    "        \n",
    "    messages2 = create_message_for_comparison(code_string, all_queries)\n",
    "\n",
    "    # Make the API call to GPT-4o-mini for comparison\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages2,\n",
    "        max_tokens=700,\n",
    "        temperature=0.01\n",
    "    )\n",
    "\n",
    "    # Extract and return the most similar query from the response\n",
    "    response_content = response.choices[0].message.content\n",
    "    # printer(response_content)\n",
    "    \n",
    "    searched_index = searching2(response_content, reference)\n",
    "    print(searched_index)\n",
    "\n",
    "    sorted_set.append(searched_index)\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Exectution time :\",end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f3cb4d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 771)],\n",
       " [(1, 990)],\n",
       " [],\n",
       " [(3, 615)],\n",
       " [(4, 737)],\n",
       " [(5, 878)],\n",
       " [(6, 771)],\n",
       " [(7, 385)],\n",
       " [(8, 751)],\n",
       " [(9, 321)],\n",
       " [],\n",
       " [(11, 385)],\n",
       " [(12, 818)],\n",
       " [(13, 156)],\n",
       " [(14, 627)],\n",
       " [(15, 452)],\n",
       " [(16, 57)],\n",
       " [(17, 1018)],\n",
       " [(18, 92)],\n",
       " [(19, 362)],\n",
       " [(20, 755)],\n",
       " [(21, 540)],\n",
       " [(22, 558)],\n",
       " [(23, 49)],\n",
       " [(24, 797)],\n",
       " [(25, 196)],\n",
       " [(26, 667)],\n",
       " [(27, 535)],\n",
       " [(28, 937)],\n",
       " [(29, 918)],\n",
       " [(30, 117)],\n",
       " [(31, 308)],\n",
       " [(32, 314)],\n",
       " [(33, 287)],\n",
       " [(34, 447)],\n",
       " [(35, 116)],\n",
       " [(36, 223)],\n",
       " [(37, 556)],\n",
       " [(38, 84)],\n",
       " [(39, 193)],\n",
       " [(40, 206)],\n",
       " [(41, 804)],\n",
       " [(42, 798)],\n",
       " [(43, 663)],\n",
       " [(44, 328)],\n",
       " [(45, 643)],\n",
       " [(46, 631)],\n",
       " [(47, 933)],\n",
       " [(48, 1001)],\n",
       " [(49, 771)],\n",
       " [(50, 246)],\n",
       " [(51, 40)],\n",
       " [],\n",
       " [(53, 777)],\n",
       " [(54, 833)],\n",
       " [(55, 225)],\n",
       " [(56, 532)],\n",
       " [(57, 927)],\n",
       " [],\n",
       " [(59, 576)],\n",
       " [(60, 351)],\n",
       " [(61, 303)],\n",
       " [],\n",
       " [],\n",
       " [(64, 613)],\n",
       " [(65, 229)],\n",
       " [(66, 146)],\n",
       " [(67, 64)],\n",
       " [(68, 537)],\n",
       " [(69, 641)],\n",
       " [(70, 810)],\n",
       " [(71, 813)],\n",
       " [(72, 699)],\n",
       " [(73, 615)],\n",
       " [(74, 817)],\n",
       " [(75, 62)],\n",
       " [(76, 782)],\n",
       " [(77, 919)],\n",
       " [(78, 751)],\n",
       " [(79, 707)],\n",
       " [(80, 118)],\n",
       " [(81, 254)],\n",
       " [(82, 445)],\n",
       " [(83, 862)],\n",
       " [(84, 978)],\n",
       " [(85, 843)],\n",
       " [(86, 552)],\n",
       " [(87, 540)],\n",
       " [(88, 732)],\n",
       " [(89, 152)],\n",
       " [(90, 890)],\n",
       " [(91, 802)],\n",
       " [(92, 722)],\n",
       " [(93, 109)],\n",
       " [(94, 544)],\n",
       " [(95, 510)],\n",
       " [(96, 163)],\n",
       " [(97, 540)],\n",
       " [(98, 716)],\n",
       " [(99, 984)]]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d487d205-6af4-4fa4-a63d-ac1269dae947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='white-space: pre-wrap;'>\"I would like to create an animation where a piece of text reading 'ShowSubmobjectsOneByOne' appears and moves to the top of the screen. Following this, can you depict three circles appearing one after another, with the first circle at the center top, the second to the bottom left, and the third to the bottom right? After all circles are displayed, they should then disappear from the screen. I'm aiming for the text transformation to be quick, perhaps just half a second, with the rest of the animation having a standard duration.\"</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style='white-space: pre-wrap;'>951</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 5\n",
    "printer(all_queries[i])\n",
    "printer(all_indices[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c308feb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python llm_env",
   "language": "python",
   "name": "your_env_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
